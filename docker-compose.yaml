version: '3'
services:
  reverse-proxy:
    image: traefik:v2.3
    command:
      - "--entryPoints.web.address=:80"
      - "--api.insecure=true"
      - "--providers.docker"
      - "--providers.docker.exposedbydefault=false"
      - --accesslog=true # output log to stdout
    ports:
      - 80:80
      - 8080:8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
  random-chat:
    build: .
    restart: always
    expose:
      - "80"
    environment:
      - 'HTTP_PORT=80'
      - 'KAFKA_ADDRS=kafka:9092'
      - 'REDIS_PASSWORD=pass.123'
      - 'REDIS_ADDRS=redis-node1:7000,redis-node2:7001,redis-node3:7002,redis-node4:7003,redis-node5:7004,redis-node6:7005'
      - 'REDIS_EXPIRATION_HOURS=24'
      - 'MAX_ALLOWED_CONNS=200'
      - 'MAX_MSGS=500'
      - 'MAX_MSG_SIZE_BYTE=4096'
      - 'JWT_SECRET=mysecret'
      - 'JWT_EXPIRATION_SECONDS=86400'
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.random-chat.rule=PathPrefix(`/`)"
      - "traefik.http.routers.random-chat.entrypoints=web"
      - "traefik.http.routers.random-chat.service=random-chat"
      - "traefik.http.services.random-chat.loadbalancer.server.port=80"
    depends_on:
      - redis-cluster-creator
      - zookeeper
      - kafka
  redis-node1:
    build:
      context: redis
    ports:
      - 7000:7000
      - 17000:17000
    restart: always
    volumes:
      - redis-node1-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf, --port,"7000", --cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node2:
    build:
      context: redis
    ports:
      - 7001:7001
      - 17001:17001
    restart: always
    volumes:
      - redis-node2-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7001",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node3:
    build:
      context: redis
    ports:
      - 7002:7002
      - 17002:17002
    restart: always
    volumes:
      - redis-node3-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7002",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node4:
    build:
      context: redis
    ports:
      - 7003:7003
      - 17003:17003
    restart: always
    volumes:
      - redis-node4-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7003",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node5:
    build:
      context: redis
    ports:
      - 7004:7004
      - 17004:17004
    restart: always
    volumes:
      - redis-node5-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7004",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node6:
    build:
      context: redis
    ports:
      - 7005:7005
      - 17005:17005
    restart: always
    volumes:
      - redis-node6-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7005",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-cluster-creator:
    image: redis:6.2.6
    entrypoint: [/bin/sh,-c,'echo "yes" | redis-cli -a ${REDIS_PASSWD} --cluster create ${REDIS_CLUSTER_IP}:7000 ${REDIS_CLUSTER_IP}:7001 ${REDIS_CLUSTER_IP}:7002 ${REDIS_CLUSTER_IP}:7003 ${REDIS_CLUSTER_IP}:7004 ${REDIS_CLUSTER_IP}:7005 --cluster-replicas 1']
    depends_on:
      - redis-node1
      - redis-node2
      - redis-node3
      - redis-node4
      - redis-node5
      - redis-node6
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181   
  kafka:
    image: confluentinc/cp-kafka:7.0.1
    restart: unless-stopped
    environment:
      KAFKA_LOG_RETENTION_MINUTES: 1440 # save data for 24hrs
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      # This is required when you are running with a single-node cluster
      # specify the replication factor for the __consumer_offsets topic
      # __consumer_offsets topic preserves consumer offsets when consumer group commits offsets to Kafka
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # when applications attempt to produce, consume, or fetch metadata for a non-existent topic, 
      # Kafka will automatically create the topic with the default replication factor and number of partitions
      # which is true by default
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      - zookeeper
volumes:
  redis-node1-data:
  redis-node2-data:
  redis-node3-data:
  redis-node4-data:
  redis-node5-data:
  redis-node6-data:
