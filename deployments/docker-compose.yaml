version: '3'
services:
  reverse-proxy:
    image: traefik:v2.3
    command:
      - "--entryPoints.web.address=:80"
      - "--api.insecure=true"
      - "--providers.docker"
      - "--providers.docker.exposedbydefault=false"
      - --accesslog=true # output log to stdout
    ports:
      - 80:80
      - 8080:8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
  web:
    image: minghsu0107/random-chat-web:kafka
    restart: always
    expose:
      - "80"
    environment:
      APP: web
      HTTP_PORT: "80"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.rcweb.rule=PathPrefix(`/`)"
      - "traefik.http.routers.rcweb.entrypoints=web"
      - "traefik.http.routers.rcweb.service=rcweb"
      - "traefik.http.services.rcweb.loadbalancer.server.port=80"
  random-chat:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    expose:
      - "80"
    environment:
      APP: chat
      HTTP_PORT: "80"
      KAFKA_ADDRS: kafka:9092
      REDIS_PASSWORD: pass.123
      REDIS_ADDRS: redis-node1:7000,redis-node2:7001,redis-node3:7002,redis-node4:7003,redis-node5:7004,redis-node6:7005
      REDIS_EXPIRATION_HOURS: "24"
      MAX_ALLOWED_CONNS: "200"
      MAX_MSGS: "500"
      MAX_MSG_SIZE_BYTE: "4096"
      JWT_SECRET: "mysecret"
      JWT_EXPIRATION_SECONDS: "86400"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.random-chat.rule=PathPrefix(`/api`)"
      - "traefik.http.routers.random-chat.entrypoints=web"
      - "traefik.http.routers.random-chat.service=random-chat"
      - "traefik.http.services.random-chat.loadbalancer.server.port=80"
    depends_on:
      - redis-cluster-creator
      - zookeeper
      - kafka
  uploader:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    depends_on:
      - minio
    expose:
      - "80"
    environment:
      APP: upload
      HTTP_PORT: "80"
      S3_ENDPOINT: http://minio:9000
      S3_REGION: us-east-1
      S3_BUCKET: myfilebucket
      AWS_ACCESS_KEY_ID: testaccesskey
      AWS_SECRET_KEY: testsecret
      JWT_SECRET: "mysecret"
      JWT_EXPIRATION_SECONDS: "86400"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.uploader.rule=PathPrefix(`/api/file`)"
      - "traefik.http.routers.uploader.entrypoints=web"
      - "traefik.http.routers.uploader.service=uploader"
      - "traefik.http.services.uploader.loadbalancer.server.port=80"
  minio:
    image: minio/minio:RELEASE.2021-03-17T02-33-02Z@sha256:d33b2e9559ee59acf7591cd83cb7238837158a316956e6140e6692a8e4e12fe9
    volumes:
      - minio_data:/export
    command: server /export
    environment:
      MINIO_ACCESS_KEY: testaccesskey
      MINIO_SECRET_KEY: testsecret
    ports:
      - "9000:9000"
  createbucket:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add myminio http://minio:9000 testaccesskey testsecret;
      /usr/bin/mc mb myminio/myfilebucket;
      /usr/bin/mc policy set public myminio/myfilebucket;
      exit 0;
      "
  redis-node1:
    build:
      context: redis
    ports:
      - 7000:7000
      - 17000:17000
    restart: always
    volumes:
      - redis-node1-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf, --port,"7000", --cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node2:
    build:
      context: redis
    ports:
      - 7001:7001
      - 17001:17001
    restart: always
    volumes:
      - redis-node2-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7001",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node3:
    build:
      context: redis
    ports:
      - 7002:7002
      - 17002:17002
    restart: always
    volumes:
      - redis-node3-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7002",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node4:
    build:
      context: redis
    ports:
      - 7003:7003
      - 17003:17003
    restart: always
    volumes:
      - redis-node4-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7003",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node5:
    build:
      context: redis
    ports:
      - 7004:7004
      - 17004:17004
    restart: always
    volumes:
      - redis-node5-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7004",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node6:
    build:
      context: redis
    ports:
      - 7005:7005
      - 17005:17005
    restart: always
    volumes:
      - redis-node6-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7005",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-cluster-creator:
    image: redis:6.2.6
    entrypoint: [/bin/sh,-c,'echo "yes" | redis-cli -a ${REDIS_PASSWD} --cluster create ${REDIS_CLUSTER_IP}:7000 ${REDIS_CLUSTER_IP}:7001 ${REDIS_CLUSTER_IP}:7002 ${REDIS_CLUSTER_IP}:7003 ${REDIS_CLUSTER_IP}:7004 ${REDIS_CLUSTER_IP}:7005 --cluster-replicas 1']
    depends_on:
      - redis-node1
      - redis-node2
      - redis-node3
      - redis-node4
      - redis-node5
      - redis-node6
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181   
  kafka:
    image: confluentinc/cp-kafka:7.0.1
    restart: unless-stopped
    environment:
      KAFKA_LOG_RETENTION_MINUTES: 1440 # save data for 24hrs
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      # This is required when you are running with a single-node cluster
      # specify the replication factor for the __consumer_offsets topic
      # __consumer_offsets topic preserves consumer offsets when consumer group commits offsets to Kafka
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # when applications attempt to produce, consume, or fetch metadata for a non-existent topic, 
      # Kafka will automatically create the topic with the default replication factor and number of partitions
      # which is true by default
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      - zookeeper
volumes:
  minio_data:
  redis-node1-data:
  redis-node2-data:
  redis-node3-data:
  redis-node4-data:
  redis-node5-data:
  redis-node6-data:
