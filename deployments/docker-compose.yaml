version: '3'
services:
  reverse-proxy:
    image: traefik:v2.3
    command:
      - "--entryPoints.web.address=:80"
      - "--api.insecure=true"
      - "--providers.docker"
      - "--providers.docker.exposedbydefault=false"
      - --accesslog=true # output log to stdout
      - --tracing=true
      - --tracing.jaeger=true
      - --tracing.jaeger.collector.endpoint=http://jaeger:14268/api/traces?format=jaeger.thrift
      - --tracing.jaeger.traceContextHeaderName=uber-trace-id
      - --tracing.jaeger.gen128Bit
      - --tracing.jaeger.samplingParam=1.0
    ports:
      - 80:80
      - 8080:8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
  web:
    image: minghsu0107/random-chat-web:kafka
    restart: always
    expose:
      - "80"
    environment:
      WEB_HTTP_PORT: "80"
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.rcweb.rule=PathPrefix(`/`)"
      - "traefik.http.routers.rcweb.entrypoints=web"
      - "traefik.http.routers.rcweb.service=rcweb"
      - "traefik.http.services.rcweb.loadbalancer.server.port=80"
  random-chat:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    expose:
      - "80"
    command:
      - chat
    environment:
      CHAT_HTTP_PORT: "80"
      CHAT_HTTP_MAXCONN: "200"
      CHAT_KAFKA_ADDRS: kafka:9092
      CHAT_REDIS_PASSWORD: pass.123
      CHAT_REDIS_ADDRS: redis-node1:7000,redis-node2:7001,redis-node3:7002,redis-node4:7003,redis-node5:7004,redis-node6:7005
      CHAT_REDIS_EXPIRATIONHOUR: "24"
      CHAT_MESSAGE_MAXNUM: "500"
      CHAT_MESSAGE_MAXSIZEBYTE: "4096"
      CHAT_JWT_SECRET: ${JWT_SECRET}
      CHAT_JWT_EXPIRATIONSECOND: "86400"
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.random-chat.rule=PathPrefix(`/api`)"
      - "traefik.http.routers.random-chat.entrypoints=web"
      - "traefik.http.routers.random-chat.service=random-chat"
      - "traefik.http.services.random-chat.loadbalancer.server.port=80"
    depends_on:
      - redis-cluster-creator
      - zookeeper
      - kafka
  uploader:
    image: minghsu0107/random-chat-api:kafka
    restart: always
    depends_on:
      - minio
    expose:
      - "80"
    command:
      - uploader
    environment:
      UPLOADER_HTTP_PORT: "80"
      UPLOADER_S3_ENDPOINT: http://minio:9000
      UPLOADER_S3_DISABLESSL: "true"
      UPLOADER_S3_REGION: us-east-1
      UPLOADER_S3_BUCKET: myfilebucket
      UPLOADER_S3_ACCESSKEY: testaccesskey
      UPLOADER_S3_SECRETKEY: testsecret
      UPLOADER_JWT_SECRET: ${JWT_SECRET}
      OBSERVABILITY_PROMETHEUS_PORT: "8080"
      OBSERVABILITY_TRACING_JAEGERURL: http://jaeger:14268/api/traces
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.uploader.rule=PathPrefix(`/api/file`)"
      - "traefik.http.routers.uploader.entrypoints=web"
      - "traefik.http.routers.uploader.service=uploader"
      - "traefik.http.services.uploader.loadbalancer.server.port=80"
  minio:
    image: minio/minio:RELEASE.2021-03-17T02-33-02Z@sha256:d33b2e9559ee59acf7591cd83cb7238837158a316956e6140e6692a8e4e12fe9
    volumes:
      - minio_data:/export
    command: server /export
    environment:
      MINIO_ACCESS_KEY: testaccesskey
      MINIO_SECRET_KEY: testsecret
    ports:
      - "9000:9000"
  createbucket:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add myminio http://minio:9000 testaccesskey testsecret;
      /usr/bin/mc mb myminio/myfilebucket;
      /usr/bin/mc policy set public myminio/myfilebucket;
      exit 0;
      "
  prometheus:
    image: prom/prometheus:v2.25.2
    volumes:
      - ./prometheus/prometheus.yaml:/etc/prometheus/prometheus.yaml
    command: --config.file=/etc/prometheus/prometheus.yaml
    ports:
      - 9090:9090
  jaeger:
    image: jaegertracing/all-in-one:1.22
    ports:
      - 14268:14268
      - 16686:16686
  redis-node1:
    build:
      context: redis
    ports:
      - 7000:7000
      - 17000:17000
    restart: always
    volumes:
      - redis-node1-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf, --port,"7000", --cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node2:
    build:
      context: redis
    ports:
      - 7001:7001
      - 17001:17001
    restart: always
    volumes:
      - redis-node2-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7001",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node3:
    build:
      context: redis
    ports:
      - 7002:7002
      - 17002:17002
    restart: always
    volumes:
      - redis-node3-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7002",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node4:
    build:
      context: redis
    ports:
      - 7003:7003
      - 17003:17003
    restart: always
    volumes:
      - redis-node4-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7003",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node5:
    build:
      context: redis
    ports:
      - 7004:7004
      - 17004:17004
    restart: always
    volumes:
      - redis-node5-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7004",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-node6:
    build:
      context: redis
    ports:
      - 7005:7005
      - 17005:17005
    restart: always
    volumes:
      - redis-node6-data:/data
    entrypoint: [redis-server, /etc/redis/rediscluster.conf,--port,"7005",--cluster-announce-ip,"${REDIS_CLUSTER_IP}"]
  redis-cluster-creator:
    image: redis:6.2.6
    entrypoint: [/bin/sh,-c,'echo "yes" | redis-cli -a ${REDIS_PASSWD} --cluster create ${REDIS_CLUSTER_IP}:7000 ${REDIS_CLUSTER_IP}:7001 ${REDIS_CLUSTER_IP}:7002 ${REDIS_CLUSTER_IP}:7003 ${REDIS_CLUSTER_IP}:7004 ${REDIS_CLUSTER_IP}:7005 --cluster-replicas 1']
    depends_on:
      - redis-node1
      - redis-node2
      - redis-node3
      - redis-node4
      - redis-node5
      - redis-node6
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    restart: unless-stopped
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181   
  kafka:
    image: confluentinc/cp-kafka:7.0.1
    restart: unless-stopped
    environment:
      KAFKA_LOG_RETENTION_MINUTES: 1440 # save data for 24hrs
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      # This is required when you are running with a single-node cluster
      # specify the replication factor for the __consumer_offsets topic
      # __consumer_offsets topic preserves consumer offsets when consumer group commits offsets to Kafka
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # when applications attempt to produce, consume, or fetch metadata for a non-existent topic, 
      # Kafka will automatically create the topic with the default replication factor and number of partitions
      # which is true by default
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      - zookeeper
volumes:
  minio_data:
  redis-node1-data:
  redis-node2-data:
  redis-node3-data:
  redis-node4-data:
  redis-node5-data:
  redis-node6-data:
